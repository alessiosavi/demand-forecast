{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "439788f1",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602a75c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import os\n",
    "from torch import optim\n",
    "import pickle\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd54a8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_params = {}\n",
    "\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    # Define the hyperparameters to tune\n",
    "    sku_emb_dim = trial.suggest_categorical(\"sku_emb_dim\", choices=[32, 64, 128, 256])\n",
    "    cat_emb_dims = trial.suggest_categorical(\"cat_emb_dims\", choices=[32, 64, 128, 256])\n",
    "    lstm_hidden_size = trial.suggest_categorical(\n",
    "        \"lstm_hidden_size\", choices=[32, 64, 128, 256]\n",
    "    )\n",
    "    linear_hidden_size = trial.suggest_categorical(\n",
    "        \"linear_hidden_size\", choices=[64, 128, 192, 256, 512]\n",
    "    )\n",
    "    lstm_bidirectional = trial.suggest_categorical(\n",
    "        \"lstm_bidirectional\", choices=[True, False]\n",
    "    )\n",
    "    lstm_layers = trial.suggest_categorical(\"lstm_layers\", choices=[2, 3, 4, 5, 6])\n",
    "    learning_rate = trial.suggest_categorical(\n",
    "        \"learning_rate\", choices=[0.01, 0.001, 0.0001]\n",
    "    )\n",
    "    dropout = trial.suggest_categorical(\"dropout\", choices=[0, 0.1, 0.3, 0.5])\n",
    "    flatten = trial.suggest_categorical(\"flatten\", choices=[True, False])\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", choices=[64, 128, 256, 512])\n",
    "\n",
    "    params = [\n",
    "        sku_emb_dim,\n",
    "        cat_emb_dims,\n",
    "        lstm_hidden_size,\n",
    "        linear_hidden_size,\n",
    "        lstm_bidirectional,\n",
    "        lstm_layers,\n",
    "        learning_rate,\n",
    "        dropout,\n",
    "        batch_size,\n",
    "    ]\n",
    "    key = \"_\".join(map(str, params))\n",
    "    if key in trials_params:\n",
    "        print(f\"Skipping trial {trial.params} [already run]\")\n",
    "        return trials_params[key]\n",
    "    num_epochs = 20\n",
    "    device, dl_train, dl_test, ds_train, ds_test = init_ds(batch_size, 4)\n",
    "    model = DemandForecastingModel(\n",
    "        sku_vocab_size,\n",
    "        sku_emb_dim,\n",
    "        cat_features_shapes,\n",
    "        cat_emb_dims,\n",
    "        time_features_dim,\n",
    "        lstm_bidirectional,\n",
    "        lstm_hidden_size,\n",
    "        lstm_layers,\n",
    "        linear_hidden_size,\n",
    "        dropout,\n",
    "        n_out,\n",
    "    ).to(device)\n",
    "    early_stop = {\"patience\": 10, \"min_delta\": 0.5}\n",
    "    # Define the loss functions and optimizer\n",
    "    regression_criterion = nn.MSELoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        patience=5,\n",
    "        factor=0.5,\n",
    "        threshold=early_stop[\"min_delta\"] * 2,\n",
    "        mode=\"min\",\n",
    "        # verbose=True,\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    train_model(\n",
    "        model,\n",
    "        dl_train,\n",
    "        dl_test,\n",
    "        regression_criterion,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        num_epochs,\n",
    "        batch_size,\n",
    "        device,\n",
    "        early_stop=early_stop,\n",
    "        flatten=flatten,\n",
    "    )\n",
    "\n",
    "    # Validate the model\n",
    "    val_metrics = validate_model(\n",
    "        model,\n",
    "        dl_test,\n",
    "        regression_criterion,\n",
    "        batch_size,\n",
    "        True,\n",
    "    )\n",
    "    _collect()\n",
    "    trials_params[key] = val_metrics[\"flatten_mse\"]\n",
    "    return val_metrics[\"flatten_mse\"]\n",
    "\n",
    "\n",
    "_collect()\n",
    "study_name = \"study-v12\"  # Unique identifier of the study.\n",
    "storage_name = \"sqlite:///{}.db\".format(study_name)\n",
    "\n",
    "sampler = optuna.samplers.TPESampler(seed=seed)\n",
    "sampler_fname = f\"{study_name}-sampler.pkl\"\n",
    "if os.path.exists(sampler_fname):\n",
    "    sampler = pickle.load(open(sampler_fname, \"rb\"))\n",
    "else:\n",
    "    with open(f\"{study_name}-sampler.pkl\", \"wb\") as fout:\n",
    "        pickle.dump(sampler, fout)\n",
    "try:\n",
    "    study = optuna.create_study(\n",
    "        direction=\"minimize\",\n",
    "        study_name=study_name,\n",
    "        storage=storage_name,\n",
    "        load_if_exists=True,\n",
    "        sampler=sampler,\n",
    "    )\n",
    "    # Optimize the study\n",
    "    study.optimize(\n",
    "        objective,\n",
    "        timeout=datetime.timedelta(minutes=60).seconds,\n",
    "        gc_after_trial=True,\n",
    "        show_progress_bar=True,\n",
    "        catch=[Exception],\n",
    "    )\n",
    "except Exception as e:\n",
    "    with open(f\"{study_name}-sampler.pkl\", \"wb\") as fout:\n",
    "        pickle.dump(sampler, fout)\n",
    "    df_optuna = study.trials_dataframe().sort_values([\"value\"])\n",
    "    df_optuna.to_csv(f\"{study_name}.csv\", index=False)\n",
    "\n",
    "# Print the best parameters and value\n",
    "df_optuna = study.trials_dataframe().sort_values([\"value\"])\n",
    "df_optuna.to_csv(f\"{study_name}.csv\", index=False)\n",
    "param_column = [col for col in df_optuna.columns if \"param\" in col]\n",
    "df_optuna.drop_duplicates(param_column, inplace=True)\n",
    "display(df_optuna.head(20))\n",
    "df_param = df_optuna.head(1)[param_column]\n",
    "df_param.columns = [c.removeprefix(\"params_\") for c in df_param.columns]\n",
    "best_params = df_param.iloc[0].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1674910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best parameters and value\n",
    "df_optuna = study.trials_dataframe().sort_values([\"value\"])\n",
    "df_optuna.to_csv(f\"{study_name}.csv\", index=False)\n",
    "param_column = [col for col in df_optuna.columns if \"param\" in col]\n",
    "df_optuna.drop_duplicates(param_column, inplace=True)\n",
    "display(df_optuna.head(20))\n",
    "df_param = df_optuna.head(1)[param_column]\n",
    "df_param.columns = [c.removeprefix(\"params_\") for c in df_param.columns]\n",
    "best_params = df_param.iloc[0].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899dc412",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.visualization import (\n",
    "    plot_contour,\n",
    "    plot_edf,\n",
    "    plot_optimization_history,\n",
    "    plot_parallel_coordinate,\n",
    "    plot_param_importances,\n",
    "    plot_rank,\n",
    "    plot_slice,\n",
    "    plot_timeline,\n",
    ")\n",
    "\n",
    "base_folder = f\"plotly/{study_name}/\"\n",
    "os.makedirs(base_folder, exist_ok=True)\n",
    "for _plot in [\n",
    "    plot_contour,\n",
    "    plot_edf,\n",
    "    plot_optimization_history,\n",
    "    plot_parallel_coordinate,\n",
    "    plot_param_importances,\n",
    "    plot_rank,\n",
    "    plot_slice,\n",
    "    plot_timeline,\n",
    "]:\n",
    "\n",
    "    try:\n",
    "        _name = _plot.__str__().split(\" \")[1]\n",
    "        fig = _plot(study)\n",
    "        fig.write_html(f\"{base_folder}/{_name}.html\")\n",
    "    except Exception as e:\n",
    "        print(f\"unable to plot {_name} due to {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5155a3d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
